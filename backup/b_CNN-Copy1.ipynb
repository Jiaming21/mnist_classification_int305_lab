{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08adbf4e-9947-42d9-9de2-53642d92fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, matthews_corrcoef, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86676630-63a4-47ce-a1de-00ad7b7815cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_datasets_info = torch.load('/root/autodl-tmp/data/saved_datasets.pth', weights_only=False)\n",
    "train_dataset = loaded_datasets_info['train_dataset']\n",
    "test_dataset = loaded_datasets_info['test_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fd37380-5869-4686-a49e-8efc83c251da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "loaded_train_dataset = DataLoader(train_dataset, batch_size = batch_size, shuffle = False)\n",
    "loaded_test_dataset = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305eeac2-6805-47f5-bbbe-585e7e6a56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "        )\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(576, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e945dca8-3abf-4485-8545-1b4290026319",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdd49a46-df0b-4459-bd2e-164d01694342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.096076072370433\n",
      "Epoch 2/10, Loss: 0.9259225890847523\n",
      "Epoch 3/10, Loss: 0.7174603522022901\n",
      "Epoch 4/10, Loss: 0.6413480141689214\n",
      "Epoch 5/10, Loss: 0.5525594813361668\n",
      "Epoch 6/10, Loss: 0.5270170656357491\n",
      "Epoch 7/10, Loss: 0.5061076240224204\n",
      "Epoch 8/10, Loss: 0.4707066361641534\n",
      "Epoch 9/10, Loss: 0.46188682863761005\n",
      "Epoch 10/10, Loss: 0.43728336004801754\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_train_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / (len(loaded_train_dataset) / batch_size)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9316c4d-350b-4008-9566-e9985c066f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9dc138a-4df7-4164-bc54-1c32c6ad2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiclass_metrics(true_labels, predicted_labels, predicted_probabilities, num_classes):\n",
    "    sensitivity_per_class = []\n",
    "    specificity_per_class = []\n",
    "    auc_per_class = []\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        true_binary = (np.array(true_labels) == i).astype(int)\n",
    "        pred_binary = (np.array(predicted_labels) == i).astype(int)\n",
    "\n",
    "        cm = confusion_matrix(true_binary, pred_binary, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        sensitivity_per_class.append(sensitivity)\n",
    "        specificity_per_class.append(specificity)\n",
    "\n",
    "        if predicted_probabilities is not None:\n",
    "            auc = roc_auc_score(true_binary, predicted_probabilities[:, i]) if len(np.unique(true_binary)) > 1 else 0\n",
    "            auc_per_class.append(auc)\n",
    "\n",
    "    avg_sensitivity = np.mean(sensitivity_per_class)\n",
    "    avg_specificity = np.mean(specificity_per_class)\n",
    "    avg_auc = np.mean(auc_per_class) if auc_per_class else 0\n",
    "\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
    "    print(f\"Average Sensitivity: {avg_sensitivity:.4f}\")\n",
    "    print(f\"Average Specificity: {avg_specificity:.4f}\")\n",
    "    print(f\"Average AUC: {avg_auc:.4f}\")\n",
    "    \n",
    "    #for i in range(num_classes):\n",
    "    #    print(f\"Class {i}: Sensitivity = {sensitivity_per_class[i]:.4f}, Specificity = {specificity_per_class[i]:.4f}\")\n",
    "    #    if predicted_probabilities is not None:\n",
    "    #        print(f\"Class {i}: AUC = {auc_per_class[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3680c87-985b-4f75-8c9c-a4ee0b201957",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = []\n",
    "true_labels = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_train_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)      \n",
    "        outputs = model(inputs)\n",
    "        predicted_probabilities.extend(outputs.tolist())\n",
    "        true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fb1a2ab-283c-410e-aeb2-1eb27a4ba72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "[5 0 4 ... 5 6 8]\n",
      "tensor([[9.5244e-16, 4.2310e-20, 1.6396e-21,  ..., 2.7411e-20, 1.6484e-14,\n",
      "         8.5069e-14],\n",
      "        [1.0000e+00, 1.3299e-24, 2.8630e-16,  ..., 2.8158e-21, 4.5693e-21,\n",
      "         1.4943e-16],\n",
      "        [3.7910e-24, 3.2167e-16, 6.9439e-22,  ..., 6.8377e-19, 8.4983e-19,\n",
      "         5.3311e-11],\n",
      "        ...,\n",
      "        [6.7695e-19, 9.9230e-26, 8.8108e-23,  ..., 4.3038e-23, 1.7075e-19,\n",
      "         1.2504e-17],\n",
      "        [8.9366e-19, 5.6034e-24, 4.1750e-16,  ..., 5.3479e-30, 2.2247e-21,\n",
      "         3.0061e-25],\n",
      "        [2.2347e-14, 2.0734e-17, 1.4224e-11,  ..., 8.6425e-20, 1.0000e+00,\n",
      "         3.2686e-10]])\n"
     ]
    }
   ],
   "source": [
    "true_labels_ = np.argmax(true_labels, axis=-1)\n",
    "print(true_labels_)\n",
    "\n",
    "predicted_labels = np.argmax(predicted_probabilities, axis=-1)\n",
    "print(predicted_labels)\n",
    "\n",
    "preds = torch.tensor(predicted_probabilities)\n",
    "preds = F.softmax(preds, dim=-1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a25ece8-501d-41b1-8f21-e8ca48a6f640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9629    0.9983    0.9803      5923\n",
      "           1     0.9882    0.9964    0.9923      6742\n",
      "           2     0.9888    0.9906    0.9897      5958\n",
      "           3     0.9982    0.9741    0.9860      6131\n",
      "           4     0.9872    0.9940    0.9906      5842\n",
      "           5     0.9836    0.9930    0.9883      5421\n",
      "           6     0.9946    0.9870    0.9908      5918\n",
      "           7     0.9928    0.9874    0.9901      6265\n",
      "           8     0.9932    0.9798    0.9865      5851\n",
      "           9     0.9900    0.9781    0.9840      5949\n",
      "\n",
      "    accuracy                         0.9879     60000\n",
      "   macro avg     0.9879    0.9879    0.9878     60000\n",
      "weighted avg     0.9880    0.9879    0.9879     60000\n",
      "\n",
      "Accuracy: 0.9879\n",
      "Matthews Correlation Coefficient (MCC): 0.9866\n",
      "Average Sensitivity: 0.9879\n",
      "Average Specificity: 0.9987\n",
      "Average AUC: 0.9998\n",
      "Class 0: Sensitivity = 0.9983, Specificity = 0.9958\n",
      "Class 0: AUC = 0.9999\n",
      "Class 1: Sensitivity = 0.9964, Specificity = 0.9985\n",
      "Class 1: AUC = 0.9999\n",
      "Class 2: Sensitivity = 0.9906, Specificity = 0.9988\n",
      "Class 2: AUC = 0.9998\n",
      "Class 3: Sensitivity = 0.9741, Specificity = 0.9998\n",
      "Class 3: AUC = 0.9998\n",
      "Class 4: Sensitivity = 0.9940, Specificity = 0.9986\n",
      "Class 4: AUC = 0.9999\n",
      "Class 5: Sensitivity = 0.9930, Specificity = 0.9984\n",
      "Class 5: AUC = 0.9998\n",
      "Class 6: Sensitivity = 0.9870, Specificity = 0.9994\n",
      "Class 6: AUC = 0.9999\n",
      "Class 7: Sensitivity = 0.9874, Specificity = 0.9992\n",
      "Class 7: AUC = 0.9998\n",
      "Class 8: Sensitivity = 0.9798, Specificity = 0.9993\n",
      "Class 8: AUC = 0.9997\n",
      "Class 9: Sensitivity = 0.9781, Specificity = 0.9989\n",
      "Class 9: AUC = 0.9996\n"
     ]
    }
   ],
   "source": [
    "calculate_multiclass_metrics(true_labels_, predicted_labels, preds, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a7f14-eae0-4e31-9b3d-8eb2cbdcd09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25500b28-0706-4817-a87b-20aac0aade96",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = []  \n",
    "true_labels = []  \n",
    "with torch.set_grad_enabled(False): \n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_test_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)    \n",
    "        outputs = model(inputs)\n",
    "        predicted_probabilities.extend(outputs.tolist())\n",
    "        true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0167c72-831d-4cd5-9366-2330e4712b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "tensor([[1.6281e-17, 1.2736e-11, 1.0172e-08,  ..., 1.0000e+00, 7.3936e-10,\n",
      "         4.9919e-07],\n",
      "        [2.1103e-21, 4.7740e-16, 1.0000e+00,  ..., 2.9388e-15, 4.6941e-17,\n",
      "         7.6317e-20],\n",
      "        [5.5118e-19, 1.0000e+00, 2.4494e-11,  ..., 3.8591e-11, 1.1458e-12,\n",
      "         3.0847e-11],\n",
      "        ...,\n",
      "        [0.0000e+00, 6.2625e-36, 4.6637e-35,  ..., 5.3918e-34, 7.9605e-37,\n",
      "         2.5768e-24],\n",
      "        [2.7660e-23, 9.1589e-27, 5.8123e-24,  ..., 1.3825e-18, 9.3278e-20,\n",
      "         1.0766e-16],\n",
      "        [7.3203e-17, 7.5009e-16, 6.3968e-21,  ..., 4.1816e-32, 5.5344e-19,\n",
      "         6.0803e-24]])\n"
     ]
    }
   ],
   "source": [
    "true_labels_ = np.argmax(true_labels, axis=-1)\n",
    "print(true_labels_)\n",
    "\n",
    "predicted_labels = np.argmax(predicted_probabilities, axis=-1)\n",
    "print(predicted_labels)\n",
    "\n",
    "preds = torch.tensor(predicted_probabilities)\n",
    "preds = F.softmax(preds, dim=-1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "113077ca-cd82-4705-87a3-74826b5a99a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9597    0.9969    0.9780       980\n",
      "           1     0.9895    0.9956    0.9925      1135\n",
      "           2     0.9894    0.9932    0.9913      1032\n",
      "           3     0.9980    0.9792    0.9885      1010\n",
      "           4     0.9878    0.9919    0.9898       982\n",
      "           5     0.9800    0.9910    0.9855       892\n",
      "           6     0.9915    0.9791    0.9853       958\n",
      "           7     0.9893    0.9864    0.9878      1028\n",
      "           8     0.9927    0.9825    0.9876       974\n",
      "           9     0.9919    0.9732    0.9825      1009\n",
      "\n",
      "    accuracy                         0.9870     10000\n",
      "   macro avg     0.9870    0.9869    0.9869     10000\n",
      "weighted avg     0.9871    0.9870    0.9870     10000\n",
      "\n",
      "Accuracy: 0.9870\n",
      "Matthews Correlation Coefficient (MCC): 0.9856\n",
      "Average Sensitivity: 0.9869\n",
      "Average Specificity: 0.9986\n",
      "Average AUC: 0.9997\n",
      "Class 0: Sensitivity = 0.9969, Specificity = 0.9955\n",
      "Class 0: AUC = 0.9999\n",
      "Class 1: Sensitivity = 0.9956, Specificity = 0.9986\n",
      "Class 1: AUC = 0.9998\n",
      "Class 2: Sensitivity = 0.9932, Specificity = 0.9988\n",
      "Class 2: AUC = 0.9998\n",
      "Class 3: Sensitivity = 0.9792, Specificity = 0.9998\n",
      "Class 3: AUC = 0.9996\n",
      "Class 4: Sensitivity = 0.9919, Specificity = 0.9987\n",
      "Class 4: AUC = 0.9999\n",
      "Class 5: Sensitivity = 0.9910, Specificity = 0.9980\n",
      "Class 5: AUC = 0.9995\n",
      "Class 6: Sensitivity = 0.9791, Specificity = 0.9991\n",
      "Class 6: AUC = 0.9993\n",
      "Class 7: Sensitivity = 0.9864, Specificity = 0.9988\n",
      "Class 7: AUC = 0.9997\n",
      "Class 8: Sensitivity = 0.9825, Specificity = 0.9992\n",
      "Class 8: AUC = 0.9998\n",
      "Class 9: Sensitivity = 0.9732, Specificity = 0.9991\n",
      "Class 9: AUC = 0.9997\n"
     ]
    }
   ],
   "source": [
    "calculate_multiclass_metrics(true_labels_, predicted_labels, preds, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8d54a-4f0c-4b04-8722-6e899b6cd643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6905c-e6d3-4e5e-a3ed-c88edc47666a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac41bde-8751-4c80-bbd0-d6488edca23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899a768-c161-4ebb-b611-3f75cff20f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b2444-209e-4029-af3d-432eece80c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "622466a4-9e1c-4780-9848-2db969e96c4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/autodl-tmp/ROC/CNN/y_val_pred.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/root/autodl-tmp/ROC/CNN/y_val_pred.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_probabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/autodl-tmp/ROC/CNN/y_val.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, true_labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/SWEdiff/lib/python3.9/site-packages/numpy/lib/npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/autodl-tmp/ROC/CNN/y_val_pred.npy'"
     ]
    }
   ],
   "source": [
    "np.save('/root/autodl-tmp/ROC/CNN/y_val_pred.npy', predicted_probabilities)\n",
    "np.save('/root/autodl-tmp/ROC/CNN/y_val.npy', true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cad8d1-ef39-46d3-b501-9e7ab7d1a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = []  \n",
    "true_labels = []  \n",
    "with torch.set_grad_enabled(False): \n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_test_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)    \n",
    "        outputs = model(inputs)\n",
    "        predicted_probabilities.extend(outputs.tolist())\n",
    "        true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61880b1e-6355-4f94-9b16-7b8c58bb2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC = metrics_output(predicted_probabilities, true_labels)\n",
    "print(roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff3d3e-6a23-4a88-bf39-019b87ba446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/root/autodl-tmp/ROC/CNN/y_test_pred.npy', predicted_probabilities)\n",
    "np.save('/root/autodl-tmp/ROC/CNN/y_test.npy', true_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWEdiff",
   "language": "python",
   "name": "swediff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
