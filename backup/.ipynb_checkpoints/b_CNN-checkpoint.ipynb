{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08adbf4e-9947-42d9-9de2-53642d92fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, matthews_corrcoef, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86676630-63a4-47ce-a1de-00ad7b7815cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1420/3936967439.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_datasets_info = torch.load('/root/autodl-tmp/data/saved_datasets.pth')\n"
     ]
    }
   ],
   "source": [
    "loaded_datasets_info = torch.load('/root/autodl-tmp/data/saved_datasets.pth')\n",
    "train_dataset = loaded_datasets_info['train_dataset']\n",
    "test_dataset = loaded_datasets_info['test_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd37380-5869-4686-a49e-8efc83c251da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "loaded_train_dataset = DataLoader(train_dataset, batch_size = batch_size, shuffle = False)\n",
    "loaded_test_dataset = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "305eeac2-6805-47f5-bbbe-585e7e6a56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "        )\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(576, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e945dca8-3abf-4485-8545-1b4290026319",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdd49a46-df0b-4459-bd2e-164d01694342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.0136951094567874\n",
      "Epoch 2/10, Loss: 0.9024833912942127\n",
      "Epoch 3/10, Loss: 0.6816384742372905\n",
      "Epoch 4/10, Loss: 0.6298759774011101\n",
      "Epoch 5/10, Loss: 0.5439084368601116\n",
      "Epoch 6/10, Loss: 0.5121743980479171\n",
      "Epoch 7/10, Loss: 0.47307930462214187\n",
      "Epoch 8/10, Loss: 0.44432091532405554\n",
      "Epoch 9/10, Loss: 0.4294630671802565\n",
      "Epoch 10/10, Loss: 0.44201848253771403\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_train_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / (len(loaded_train_dataset) / batch_size)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c3680c87-985b-4f75-8c9c-a4ee0b201957",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = []\n",
    "true_labels = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_train_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)      \n",
    "        outputs = model(inputs)\n",
    "        predicted_probabilities.extend(outputs.tolist())\n",
    "        true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b79c64f-ed08-4201-913e-f3e6231d54f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.9893394501080247\n"
     ]
    }
   ],
   "source": [
    "# auc (micro version)\n",
    "predicted_probabilities_r = np.array(predicted_probabilities).ravel()\n",
    "true_labels_r = np.array(true_labels).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(true_labels_r, predicted_probabilities_r)\n",
    "micro_auc = auc(fpr, tpr)\n",
    "print(f\"auc: {micro_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38617136-c78a-4bbb-abc6-d0510885071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "[5 0 4 ... 5 6 8]\n",
      "0.9868\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "predicted_labels_wo_oh = np.argmax(np.array(predicted_probabilities), axis=1)\n",
    "true_labels_wo_oh = np.argmax(np.array(true_labels), axis=1)\n",
    "print(true_labels_wo_oh)\n",
    "print(predicted_labels_wo_oh)\n",
    "accuracy = accuracy_score(true_labels_wo_oh, predicted_labels_wo_oh)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "661f10c2-5be8-44e8-a40a-962b85e39585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.9924841842731837\n"
     ]
    }
   ],
   "source": [
    "# f1-score (micro)\n",
    "preds = torch.tensor(predicted_probabilities)\n",
    "preds = F.softmax(preds, dim=-1)\n",
    "predicted_labels = (preds >= 0.5).int().numpy()\n",
    "predicted_labels_r = predicted_labels.ravel()\n",
    "f1_micro = f1_score(true_labels_r, predicted_labels_r, average='macro')\n",
    "print(f\"f1: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd9a4e-733e-4300-b0a2-4cae40e3f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48cf1bc-af32-44c6-a8d4-7f86d00c3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b07f8939-c720-4705-8eca-074467683b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcc\n",
    "mcc = matthews_corrcoef(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4fb1a2ab-283c-410e-aeb2-1eb27a4ba72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = np.argmax(predicted_probabilities, axis=-1)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6ec94751-523c-4a59-8aaa-dcf6f834761c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels_ = np.argmax(true_labels, axis=-1)\n",
    "true_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "67f2400f-2e37-468d-acec-c508febe08c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5923\n",
      "           1       0.98      1.00      0.99      6742\n",
      "           2       0.99      0.99      0.99      5958\n",
      "           3       1.00      0.97      0.99      6131\n",
      "           4       1.00      0.96      0.98      5842\n",
      "           5       0.97      1.00      0.98      5421\n",
      "           6       0.99      0.99      0.99      5918\n",
      "           7       1.00      0.99      0.99      6265\n",
      "           8       0.98      0.99      0.99      5851\n",
      "           9       0.97      0.99      0.98      5949\n",
      "\n",
      "    accuracy                           0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.9853\n",
      "Class 0: Sensitivity = 0.9954, Specificity = 0.9991\n",
      "Class 1: Sensitivity = 0.9985, Specificity = 0.9978\n",
      "Class 2: Sensitivity = 0.9856, Specificity = 0.9989\n",
      "Class 3: Sensitivity = 0.9749, Specificity = 0.9998\n",
      "Class 4: Sensitivity = 0.9605, Specificity = 0.9999\n",
      "Class 5: Sensitivity = 0.9965, Specificity = 0.9965\n",
      "Class 6: Sensitivity = 0.9910, Specificity = 0.9991\n",
      "Class 7: Sensitivity = 0.9861, Specificity = 0.9994\n",
      "Class 8: Sensitivity = 0.9911, Specificity = 0.9983\n",
      "Class 9: Sensitivity = 0.9877, Specificity = 0.9964\n"
     ]
    }
   ],
   "source": [
    "result = calculate_multiclass_metrics(true_labels_, predicted_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75098ef-1bbc-4868-a8de-7a2e663c9c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "18ae15d2-e7f4-4db3-b7a7-12bd77d53967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "def calculate_multiclass_metrics(true_labels, predicted_labels, predicted_probabilities, num_classes):\n",
    "    # 初始化指标存储\n",
    "    sensitivity_per_class = []\n",
    "    specificity_per_class = []\n",
    "    auc_per_class = []\n",
    "\n",
    "    # 计算 Accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # 计算 MCC\n",
    "    mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
    "\n",
    "    # 针对每个类别计算 Sensitivity, Specificity, AUC\n",
    "    for i in range(num_classes):\n",
    "        # 将当前类别设置为正类，其余类别为负类 (One-vs-All)\n",
    "        true_binary = (np.array(true_labels) == i).astype(int)\n",
    "        pred_binary = (np.array(predicted_labels) == i).astype(int)\n",
    "\n",
    "        # 计算混淆矩阵并解包 TN, FP, FN, TP\n",
    "        cm = confusion_matrix(true_binary, pred_binary, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        # 计算 Sensitivity 和 Specificity\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        sensitivity_per_class.append(sensitivity)\n",
    "        specificity_per_class.append(specificity)\n",
    "\n",
    "        # 计算 AUC（需要预测概率）\n",
    "        if predicted_probabilities is not None:\n",
    "            auc = roc_auc_score(true_binary, predicted_probabilities[:, i]) if len(np.unique(true_binary)) > 1 else 0\n",
    "            auc_per_class.append(auc)\n",
    "\n",
    "    # 平均指标计算\n",
    "    avg_sensitivity = np.mean(sensitivity_per_class)\n",
    "    avg_specificity = np.mean(specificity_per_class)\n",
    "    avg_auc = np.mean(auc_per_class) if auc_per_class else 0\n",
    "\n",
    "    # 打印逐类别指标\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(true_labels, predicted_labels, digits=4))  # 设置四位小数\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
    "    print(f\"Average Sensitivity: {avg_sensitivity:.4f}\")\n",
    "    print(f\"Average Specificity: {avg_specificity:.4f}\")\n",
    "    print(f\"Average AUC: {avg_auc:.4f}\")\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i}: Sensitivity = {sensitivity_per_class[i]:.4f}, Specificity = {specificity_per_class[i]:.4f}\")\n",
    "        if predicted_probabilities is not None:\n",
    "            print(f\"Class {i}: AUC = {auc_per_class[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbae50-1711-421e-ad3d-fd5a0cc1198f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6bf1967c-f90a-4654-8871-f561c6317d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "def calculate_multiclass_metrics(true_labels, predicted_labels, predicted_probabilities, num_classes):\n",
    "    # 初始化指标存储\n",
    "    sensitivity_per_class = []\n",
    "    specificity_per_class = []\n",
    "    auc_per_class = []\n",
    "\n",
    "    # 计算 Accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # 计算 MCC\n",
    "    mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
    "\n",
    "    # 针对每个类别计算 Sensitivity, Specificity, AUC\n",
    "    for i in range(num_classes):\n",
    "        # 将当前类别设置为正类，其余类别为负类 (One-vs-All)\n",
    "        true_binary = (np.array(true_labels) == i).astype(int)\n",
    "        pred_binary = (np.array(predicted_labels) == i).astype(int)\n",
    "\n",
    "        # 计算混淆矩阵并解包 TN, FP, FN, TP\n",
    "        tn, fp, fn, tp = confusion_matrix(true_binary, pred_binary, labels=[0, 1]).ravel()\n",
    "\n",
    "        # 计算 Sensitivity 和 Specificity\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        sensitivity_per_class.append(sensitivity)\n",
    "        specificity_per_class.append(specificity)\n",
    "\n",
    "        # 计算 AUC（需要预测概率）\n",
    "        if predicted_probabilities is not None:\n",
    "            auc = roc_auc_score(true_binary, predicted_probabilities[:, i]) if len(np.unique(true_binary)) > 1 else 0\n",
    "            auc_per_class.append(auc)\n",
    "\n",
    "    # 打印逐类别指标\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(true_labels, predicted_labels, digits=4))  # 设置四位小数\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i}: Sensitivity = {sensitivity_per_class[i]:.4f}, Specificity = {specificity_per_class[i]:.4f}\")\n",
    "        if predicted_probabilities is not None:\n",
    "            print(f\"Class {i}: AUC = {auc_per_class[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4a25ece8-501d-41b1-8f21-e8ca48a6f640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9929    0.9946    0.9938      5923\n",
      "           1     0.9842    0.9970    0.9906      6742\n",
      "           2     0.9907    0.9871    0.9889      5958\n",
      "           3     0.9980    0.9739    0.9858      6131\n",
      "           4     0.9989    0.9596    0.9789      5842\n",
      "           5     0.9635    0.9969    0.9799      5421\n",
      "           6     0.9907    0.9900    0.9904      5918\n",
      "           7     0.9944    0.9837    0.9890      6265\n",
      "           8     0.9814    0.9928    0.9871      5851\n",
      "           9     0.9687    0.9877    0.9781      5949\n",
      "\n",
      "    accuracy                         0.9864     60000\n",
      "   macro avg     0.9863    0.9863    0.9862     60000\n",
      "weighted avg     0.9866    0.9864    0.9864     60000\n",
      "\n",
      "Accuracy: 0.9864\n",
      "Matthews Correlation Coefficient (MCC): 0.9849\n",
      "Average Sensitivity: 0.9863\n",
      "Average Specificity: 0.9985\n",
      "Average AUC: 0.9998\n",
      "Class 0: Sensitivity = 0.9946, Specificity = 0.9992\n",
      "Class 0: AUC = 1.0000\n",
      "Class 1: Sensitivity = 0.9970, Specificity = 0.9980\n",
      "Class 1: AUC = 0.9999\n",
      "Class 2: Sensitivity = 0.9871, Specificity = 0.9990\n",
      "Class 2: AUC = 0.9998\n",
      "Class 3: Sensitivity = 0.9739, Specificity = 0.9998\n",
      "Class 3: AUC = 0.9996\n",
      "Class 4: Sensitivity = 0.9596, Specificity = 0.9999\n",
      "Class 4: AUC = 0.9996\n",
      "Class 5: Sensitivity = 0.9969, Specificity = 0.9962\n",
      "Class 5: AUC = 0.9998\n",
      "Class 6: Sensitivity = 0.9900, Specificity = 0.9990\n",
      "Class 6: AUC = 0.9999\n",
      "Class 7: Sensitivity = 0.9837, Specificity = 0.9993\n",
      "Class 7: AUC = 0.9998\n",
      "Class 8: Sensitivity = 0.9928, Specificity = 0.9980\n",
      "Class 8: AUC = 0.9998\n",
      "Class 9: Sensitivity = 0.9877, Specificity = 0.9965\n",
      "Class 9: AUC = 0.9996\n"
     ]
    }
   ],
   "source": [
    "# 调用函数\n",
    "calculate_multiclass_metrics(true_labels_, predicted_labels, preds, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a7f14-eae0-4e31-9b3d-8eb2cbdcd09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "39aeac53-56c8-4483-95e3-69c80269a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 8 ... 3 1 5]\n",
      "[5 2 8 ... 3 1 5]\n",
      "0.984920634920635\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "25500b28-0706-4817-a87b-20aac0aade96",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = []  \n",
    "true_labels = []  \n",
    "with torch.set_grad_enabled(False): \n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_test_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)    \n",
    "        outputs = model(inputs)\n",
    "        predicted_probabilities.extend(outputs.tolist())\n",
    "        true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "113077ca-cd82-4705-87a3-74826b5a99a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 8 ... 6 5 1]\n",
      "[2 1 8 ... 6 5 1]\n",
      "0.9863492063492063\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_wo_oh = np.argmax(np.array(predicted_probabilities), axis=1)\n",
    "true_labels_wo_oh = np.argmax(np.array(true_labels), axis=1)\n",
    "print(true_labels_wo_oh)\n",
    "print(predicted_labels_wo_oh)\n",
    "accuracy = accuracy_score(true_labels_wo_oh, predicted_labels_wo_oh)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8d54a-4f0c-4b04-8722-6e899b6cd643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6905c-e6d3-4e5e-a3ed-c88edc47666a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac41bde-8751-4c80-bbd0-d6488edca23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899a768-c161-4ebb-b611-3f75cff20f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dfed66-d7b3-4d03-abd1-503a89a603ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation by hand\n",
    "#correct_predictions = np.sum(true_labels == predicted_labels)\n",
    "#accuracy = correct_predictions / len(true_labels)\n",
    "#print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b2444-209e-4029-af3d-432eece80c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a346044-e820-48dd-8b7a-4f2bb248818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_output(predicted_probabilities, true_labels, num_classes=10):\n",
    "    \n",
    "    predicted_labels = np.argmax(np.array(predicted_probabilities), axis=1)\n",
    "    print(predicted_labels)\n",
    "    \n",
    "    true_labels = np.argmax(np.array(true_labels), axis=1)\n",
    "    print(true_labels)\n",
    "    \n",
    "    # Confusion matrix: for multi-class, we get a confusion matrix for all classes\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    # Sensitivity (Recall for each class): TP / (TP + FN) for each class\n",
    "    sensitivity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    \n",
    "    # Specificity for each class: TN / (TN + FP) for each class\n",
    "    tn = np.sum(conf_matrix) - np.sum(conf_matrix, axis=0) - np.sum(conf_matrix, axis=1) + np.diag(conf_matrix)\n",
    "    specificity = tn / (tn + np.sum(conf_matrix, axis=0) - np.diag(conf_matrix))\n",
    "    \n",
    "    # Accuracy: overall accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    # F1-score (macro average): F1 for each class, then average\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro', labels=np.arange(num_classes))\n",
    "    \n",
    "    # Matthews Correlation Coefficient (MCC) for multi-class classification\n",
    "    mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
    "    \n",
    "    # AUC: Use roc_auc_score with multi_class='ovr' for one-vs-rest ROC AUC calculation\n",
    "    auc = roc_auc_score(true_labels, predicted_probabilities, multi_class='ovr', average='macro', labels=np.arange(num_classes))\n",
    "    \n",
    "    #return auc, sensitivity, specificity, accuracy, f1, mcc\n",
    "    return sensitivity, specificity, accuracy, f1, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d290703-4305-4d49-b17a-46e825a72f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 3 3 3]\n",
      "[5 2 8 ... 3 1 5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example use:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# predicted_probs should be the probability predictions from your model (shape: [batch_size, num_classes])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# predicted_labels should be the hard predictions (shape: [batch_size,])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#sensitivity, specificity, accuracy, f1, mcc, auc = metrics_output(predicted_probabilities, true_labels, num_classes=10)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m sensitivity, specificity, accuracy, f1, mcc \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_probabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(sensitivity, specificity, accuracy, f1, mcc)\n",
      "Cell \u001b[0;32mIn[103], line 29\u001b[0m, in \u001b[0;36mmetrics_output\u001b[0;34m(predicted_probabilities, true_labels, num_classes)\u001b[0m\n\u001b[1;32m     26\u001b[0m mcc \u001b[38;5;241m=\u001b[39m matthews_corrcoef(true_labels, predicted_labels)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# AUC: Use roc_auc_score with multi_class='ovr' for one-vs-rest ROC AUC calculation\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_probabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#return auc, sensitivity, specificity, accuracy, f1, mcc\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sensitivity, specificity, accuracy, f1, mcc\n",
      "File \u001b[0;32m~/miniconda3/envs/SWEdiff/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/SWEdiff/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:634\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[0;32m~/miniconda3/envs/SWEdiff/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:707\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validation of the input y_score\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[38;5;241m1\u001b[39m, y_score\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget scores need to be probabilities for multiclass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc, i.e. they should sum up to 1.0 over classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    710\u001b[0m     )\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# validation for multiclass parameter specifications\u001b[39;00m\n\u001b[1;32m    713\u001b[0m average_options \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes"
     ]
    }
   ],
   "source": [
    "# Example use:\n",
    "# predicted_probs should be the probability predictions from your model (shape: [batch_size, num_classes])\n",
    "# predicted_labels should be the hard predictions (shape: [batch_size,])\n",
    "\n",
    "#sensitivity, specificity, accuracy, f1, mcc, auc = metrics_output(predicted_probabilities, true_labels, num_classes=10)\n",
    "sensitivity, specificity, accuracy, f1, mcc = metrics_output(predicted_probabilities, true_labels, num_classes=10)\n",
    "print(sensitivity, specificity, accuracy, f1, mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be27dfdf-52a3-4d78-97a5-8a18e34809e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[2.00770688e-33 3.91716668e-36 3.45217724e-39 ... 0.00000000e+00\n",
      "  3.09459973e-36 2.29368335e-36]\n",
      " [3.22450259e-33 3.61976413e-40 1.80637865e-37 ... 0.00000000e+00\n",
      "  3.00996668e-37 9.06860110e-39]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.12103877e-44]\n",
      " ...\n",
      " [1.31520689e-39 7.43793362e-35 2.91722314e-41 ... 1.33123354e-43\n",
      "  4.94043748e-38 1.20058015e-36]\n",
      " [1.40129846e-45 2.53635022e-43 6.87196767e-42 ... 1.26116862e-44\n",
      "  3.61619082e-41 1.38125990e-40]\n",
      " [0.00000000e+00 0.00000000e+00 1.40129846e-44 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.82554481e-42]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_probabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC)\n",
      "Cell \u001b[0;32mIn[66], line 22\u001b[0m, in \u001b[0;36mmetrics_output\u001b[0;34m(preds, labels, num_classes)\u001b[0m\n\u001b[1;32m     19\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(true_labels, predicted_probs, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m, labels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(num_classes))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Confusion matrix: for multi-class, we get a confusion matrix for all classes\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Sensitivity (Recall for each class): TP / (TP + FN) for each class\u001b[39;00m\n\u001b[1;32m     25\u001b[0m sensitivity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(conf_matrix) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(conf_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/SWEdiff/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/SWEdiff/lib/python3.9/site-packages/sklearn/metrics/_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    248\u001b[0m     {\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    259\u001b[0m ):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/SWEdiff/lib/python3.9/site-packages/sklearn/metrics/_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    114\u001b[0m             type_true, type_pred\n\u001b[1;32m    115\u001b[0m         )\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC = metrics_output(predicted_probabilities, true_labels)\n",
    "print(roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "622466a4-9e1c-4780-9848-2db969e96c4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/autodl-tmp/ROC/CNN/y_val_pred.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/root/autodl-tmp/ROC/CNN/y_val_pred.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_probabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/autodl-tmp/ROC/CNN/y_val.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, true_labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/SWEdiff/lib/python3.9/site-packages/numpy/lib/npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/autodl-tmp/ROC/CNN/y_val_pred.npy'"
     ]
    }
   ],
   "source": [
    "np.save('/root/autodl-tmp/ROC/CNN/y_val_pred.npy', predicted_probabilities)\n",
    "np.save('/root/autodl-tmp/ROC/CNN/y_val.npy', true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cad8d1-ef39-46d3-b501-9e7ab7d1a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = []  \n",
    "true_labels = []  \n",
    "with torch.set_grad_enabled(False): \n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_test_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)    \n",
    "        outputs = model(inputs)\n",
    "        predicted_probabilities.extend(outputs.tolist())\n",
    "        true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61880b1e-6355-4f94-9b16-7b8c58bb2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC = metrics_output(predicted_probabilities, true_labels)\n",
    "print(roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff3d3e-6a23-4a88-bf39-019b87ba446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/root/autodl-tmp/ROC/CNN/y_test_pred.npy', predicted_probabilities)\n",
    "np.save('/root/autodl-tmp/ROC/CNN/y_test.npy', true_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWEdiff",
   "language": "python",
   "name": "swediff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
